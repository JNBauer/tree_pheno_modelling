---
bibliography: libs/references.bib
link-citations: TRUE
output: 
  html_document:
    includes:
      in_header: html/header.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
```

```{r packages, echo=FALSE, include=FALSE}
library(chillR)
library(knitr)
library(pander)
library(ggplot2)
library(kableExtra)
library(dplyr)
```

## \# Learning Logbook

## Github corner from <https://github.com/tholman/github-corners>

## Lesson 03: Tree dormancy

**1.Put yourself in the place of a breeder who wants to calculate the temperature requirements of a newly released cultivar. Which method will you use to calculate the chilling and forcing periods? Please justify your answer.**

-   At the moment the Dynamic model is the most sophisticated approach, because of its process based idea [@fadón2020]. This leads on the other hand to more complicated calculations compared to prior methods . Models like the chilling hours are easier to calculate, but do not longer meet the needed requirements. I would recommend the breeder to use the Dynamic model, because of its high reliability. The temperature as only input is the same for all models.

\

**2.Which are the advantages (2) of the BBCH scale compared with earlies scales?**

-   covers the whole development of the plant not only the buds as with earlier scales
-   developed in a way that it can suited to all plant species
-   numerical order is more comprehensive

\

**3.Classify the following phenological stages of sweet cherry according to the BBCH scale:** ![Phenological stages of sweet cherry buds](images/03_pheno_stages.png)

1.  54/55

2.  65 could be also lower if the object in the background is a (closed) bud

3.  89

Pictures similar to 1. and 3. can be seen in the appendix of [@fadon_flower_2015].

\

------------------------------------------------------------------------

## Lesson 04: Climate change and impact projection

**1.List the main drivers of climate change at the decade to century scale, and briefly explain the mechanism through which the currently most important driver affects our climate.**

-   Greenhouse gases (Decade)

-   Aerosols (Decade)

-   Surface albedo

-   Clouds

-   Ozone

-   Volcanic and meteorite activity (Centuries)

-   Ocean currents (Centuries)

-   Milankovic cycles (Centuries)

-   Sun (Centuries)

\

-   The most important driver at the moment are Greenhouse gases (GHGs) and in particular anthropogenic CO~2~, which is mainly released by burning fossil fuels or by the production of cement. The concentration of CO~2~ in the atmosphere, which was closely correlated with the temperature in the past, is rising steadily and steeply at the moment. GHGs only absorb the reflected radiation coming from the earth and are not affected by direct radiation from the sun. This effect works like a trap, where radiation can enter, but not leave the atmosphere, which leads to an increase in temperature.

\

**2.Explain briefly what is special about temperature dynamics of the recent decades, and why we have good reasons to be concerned.**

-   In the last decades, the temperature rose steadily. The last two decades were the warmest measured since 1880. We are about to live in a world, that has never been so warm for humans or humanlike beings. The climate of the earth was always changing, but the speed of change was never so fast before. When at some point a tipping point is reached the changes cannot be undone.

**3.What does the abbreviation 'RCP' stand for, how are RCPs defined, and what is their role in projecting future climates?**

-   RCP is the abbreviation for Representative Concentration Pathways, which are defined by the additional radiated forcing in watts per square meter for the year 2100. They serve as scenarios for the future of our climate. A high scenario like RCP8.5 is caused by increasing GHG emissions, while lower scenarios can be achieved with a decrease of GHG emissions. In the case of RCP6.0, additional 6 W m^-2^ are expected for the year 2100. Multiple scenarios should be considered, since one does not know which RCP prediction will occur.

**4.Briefly describe the 4 climate impact projection methods described in the fourth video.**

-   

\

------------------------------------------------------------------------

## Lesson 05: Winter chill projections

**1.Sketch out three data access and processing challenges that had to be overcome in order to produce chill projections with state-of-the-art methodology.**

-   Climate data can easily accumulate to high amounts of computer data, which can make further processing highly demanding in time and computing. But good data management and increasingly efficient computers enable tasks like this.
-   Over time, various climate models were created and replaced with improved ones, after new insights were gathered. The changes from SRESs to SSPs and later to RCPs increased the quality of the forecasts, but for users of those forecasts it meant adapting to the new standard.
-   To achieve state-of-the-art chill projections, so called ensembles are used. These consist of several chilling models plotted together. The idea is, that there is no single correct model, but multiple models that represent the chill projections.

**2.Outline, in your understanding, the basic steps that are necessary to make such projections.**

-   setting the spatial scope for the projections
-   setting the temporal scope for the projections
-   choosing the ensemble of chill models
-   accessing the data from the past
-   prepare the data
-   generating the data for the future climate with a weather generator
-   apply the ensemble of chill models
-   plot the results

------------------------------------------------------------------------

## Lesson 06: Manual chill analysis

The data that is used in this lesson is from the inbuilt `Winters_hours_gaps` dataset. It was recorded 2008 in a walnut orchard in Winters, California. The dataset was modified by excluding a not used `Temp_gaps` column.

Table for the modified `Winters_hours_gaps` dataset

```{r, echo=FALSE}
hourtemps <- subset(Winters_hours_gaps, select = -c(Temp_gaps))

row.names(hourtemps) <- NULL
kbl(hourtemps[1:5,], escape = F) %>%
  kable_paper("hover", full_width = F, position = "left")
```

**1.Write a basic function that calculates warm hours (\>25°C)**

```{r}
WH <- function(hourtemps)
  {
  hourtemps[,"Warming_hours"] <- hourtemps$Temp>25
  return(hourtemps)
}
hourtemps_plus_WH <- WH(hourtemps)
```

\

**2.Apply this function to the Winters_hours_gaps dataset**

Table for `hourtemps_plus_WH`

```{r, echo=FALSE}
hourtemps_plus_WH <- hourtemps_plus_WH[4008:4018, 1:5]
row.names(hourtemps_plus_WH) <- NULL
hourtemps_plus_WH$Temp <- ifelse(
  hourtemps_plus_WH$Temp > 25,
  cell_spec(hourtemps_plus_WH$Temp, color = "red", bold = T),
  cell_spec(hourtemps_plus_WH$Temp, color = "green")
)

kbl(hourtemps_plus_WH, escape = F) %>%
  kable_paper("hover", full_width = F, position = "left")
```

**3.Extend this function, so that it can take start and end dates as inputs and sums up warm hours between these dates**

```{r}
WH_YEARMODA <- function(hourtemps, start_dateYEARMODA, end_dateYEARMODA, start_hour=12, end_hour=12)
{

  start_year <- as.numeric(substr(start_dateYEARMODA, 1, 4))
  start_month <- as.numeric(substr(start_dateYEARMODA, 5, 6))
  start_day <- as.numeric(substr(start_dateYEARMODA, 7, 8))

  end_year <- as.numeric(substr(end_dateYEARMODA, 1, 4))
  end_month <- as.numeric(substr(end_dateYEARMODA, 5, 6))
  end_day <- as.numeric(substr(end_dateYEARMODA, 7, 8))
  

  start_date <- which(hourtemps$Year==start_year & hourtemps$Month==start_month
                      & hourtemps$Day==start_day & hourtemps$Hour==start_hour)
  end_date <- which(hourtemps$Year==end_year & hourtemps$Month==end_month
                    & hourtemps$Day==end_day & hourtemps$Hour==end_hour)
  
  warm_hours <- WH(hourtemps)
  
  WHs <- sum(warm_hours[start_date:end_date, "Warming_hours"])
  return(WHs)
}

warming_hours_for_time_frame <- WH_YEARMODA(hourtemps, 20080501, 20080831)

```

Between the 1th of May 2008 and the 31th of August 2008, **`r warming_hours_for_time_frame`** hours over 25°C occured.

------------------------------------------------------------------------

## Lesson 07: Manual chill analysis

**1.Run the chilling() function on the Winters_hours_gap dataset**

```{r}
chilling_output <- chilling(make_JDay(Winters_hours_gaps),Start_JDay = 90, End_JDay = 100)
chilling_output
```

**2.Create your own temperature-weighting chill model using the step_model() function.**

```{r}
own_utah_steps <- data.frame(
  lower=c(-291,0,1,2,3,4,5,6),
  upper=c(0,1,2,3,4,5,6,100),
  weight=c(0,0.5,1,2,3,2,1,0))

kbl(own_utah_steps, escape = F) %>%
  kable_paper("hover", full_width = F, position = "left")

own_utah <- function(x) step_model(x,own_utah_steps)

test <- own_utah(Winters_hours_gaps$Temp)

```

**3.Run this model on the Winters_hours_gaps dataset using the tempResponse() function.**

```{r}
output<-tempResponse(make_JDay(Winters_hours_gaps),
                     Start_JDay = 90, End_JDay = 100, 
                     models=list(Own_Utah_Model=own_utah, Chill_portions=Dynamic_Model),
                     whole_record = TRUE)
kable(output) %>%
  kable_styling("striped", position = "left", font_size = 10)
```

------------------------------------------------------------------------

## Lesson 08: Manual chill analysis

**1.Choose a location of interest, find out its latitude and produce plots of daily sunrise, sunset and daylength**

I chose a location with the latitude `32`, which can be seen in the leaflet below.
```{r, echo=FALSE, message=FALSE}
require(leaflet) 
m <- leaflet() %>% setView(lng = -8, lat = 32, zoom = 16)
m %>% addProviderTiles(providers$Esri.WorldImagery) %>%
  addMiniMap(
    tiles = providers$Esri.WorldStreetMap,
    toggleDisplay = TRUE)
  
```

```{r, message=FALSE}
require(chillR)
require(ggplot2)
require(reshape2)
day_infos<-daylength(latitude=32,JDay=1:365)

days_df<-data.frame(JDay=1:365,Sunrise=day_infos$Sunrise,Sunset=day_infos$Sunset,Daylength=day_infos$Daylength)
days_df<-melt(days_df, id=c("JDay"))

ggplot(days_df, aes(JDay, value)) + geom_line(lwd=1.5) + facet_grid(cols=vars(variable)) +
  ylab("Time of Day / Daylength (Hours)") + theme_bw(base_size = 20)
```


**2.Produce an hourly dataset, based on idealized daily curves, for the KA_weather dataset (included in chillR)**
```{r}

hourly_temps_KA <- stack_hourly_temps(KA_weather, latitude=50.4)

#str(hourly_temps_KA) # to get the correct item from the list

hourly_temps_KA_df <- hourly_temps_KA$hourtemps


hourly_temps_KA_df[,"connected_timedate"] <- ISOdate(year = hourly_temps_KA_df$Year,
                                  month = hourly_temps_KA_df$Month,
                                  day = hourly_temps_KA_df$Day,
                                  hour = hourly_temps_KA_df$Hour)

ggplot(hourly_temps_KA_df[3500:3660,], aes(connected_timedate,Temp)) +
  geom_line(lwd=1.5) +
  labs(x="Date", y="Temperature in C°", title = "Hourly modelled temperature for Week 22 in 2002") +
  theme_bw(base_size = 14)
```

**3.Produce empirical temperature curve parameters for the Winters_hours_gaps dataset, and use them to predict hourly values from daily temperatures (this is very similar to the example above, but please make sure you understand what’s going on)**

```{r}
require(dplyr)

kbl(Winters_hours_gaps[1:10,], escape = F) %>%
  kable_paper("hover", full_width = F, position = "left")

coeffs<-Empirical_daily_temperature_curve(Winters_hours_gaps)

kbl(coeffs[1:10,], escape = F) %>%
  kable_paper("hover", full_width = F, position = "left")

winters_daily<-make_all_day_table(Winters_hours_gaps, input_timestep="hour")

kbl(winters_daily[1:10,], escape = F) %>%
  kable_paper("hover", full_width = F, position = "left")

winters_empirical<-Empirical_hourly_temperatures(winters_daily,coeffs)

kbl(winters_empirical[1:10,], escape = F) %>%
  kable_paper("hover", full_width = F, position = "left")

```

```{r}
require(reshape2)

winters_empirical<-winters_empirical[,c("Year","Month","Day","Hour","Temp")]
colnames(winters_empirical)[ncol(winters_empirical)]<-"Temp_empirical"

winters_ideal<-stack_hourly_temps(winters_daily, latitude=38.5)$hourtemps
winters_ideal<-winters_ideal[,c("Year","Month","Day","Hour","Temp")]
colnames(winters_ideal)[ncol(winters_ideal)]<-"Temp_ideal"

winters_temps<-merge(Winters_hours_gaps,winters_empirical, by=c("Year","Month","Day","Hour"))
winters_temps<-merge(winters_temps,winters_ideal, by=c("Year","Month","Day","Hour"))

winters_temps[,"DATE"]<-ISOdate(winters_temps$Year,winters_temps$Month, winters_temps$Day, winters_temps$Hour)

winters_temps_to_plot<-winters_temps[,c("DATE","Temp","Temp_empirical","Temp_ideal")]
winters_temps_to_plot<-winters_temps_to_plot[200:262,]
winters_temps_to_plot<-melt(winters_temps_to_plot, id=c("DATE")) 
colnames(winters_temps_to_plot)<-c("DATE","Method","Temperature")


ggplot(data=winters_temps_to_plot, aes(DATE,Temperature, colour=Method)) +
  geom_line(lwd=1.3) +
  ylab("Temperature (°C)") +
  xlab("Date") +
  ggtitle ("Different temperature methods for Winters dataset") +
  scale_color_manual(labels = c("Observed", "Ideal", "Empirical"), name="Temperature", values = c("slateblue", "peru", "mediumaquamarine")) +
  theme_bw(base_size = 14)


```

------------------------------------------------------------------------

## Lesson 09: Manual chill analysis

**1.Choose a location of interest and find the 25 closest weather stations using the handle_gsod function**

I chose a location with the latitude `32`, which can be seen in the leaflet below.
```{r, echo=FALSE, message=FALSE}
require(leaflet) 
m <- leaflet() %>% setView(lng = -84, lat = 42, zoom = 16)
m %>% addProviderTiles(providers$Esri.WorldImagery) %>%
  addMiniMap(
    tiles = providers$Esri.WorldStreetMap,
    toggleDisplay = TRUE)
  
```

```{r}
station_list<-handle_gsod(action="list_stations",
                          location=c(42,-84),
                          time_interval=c(1990,2020))

station_list
```


**2.Download weather data for the most promising station on the list**

Selecting the 2th station of the search query from task 1.
```{r}
weather<-handle_gsod(action="download_weather",
                     location=station_list$chillR_code[2],
                     time_interval=c(1990,2020))
```


**3.Convert the weather data into chillR format**

```{r}
cleaned_weather<-handle_gsod(weather)


kable(cleaned_weather$weather[1:20,]) %>%
  kable_styling("striped", position = "left", font_size = 8)
```


```{r}
DOWNLOAD = TRUE
if (DOWNLOAD == TRUE) {
  write.csv(station_list,"data/station_list.csv",row.names=FALSE)
  write.csv(weather,"data/Bonn_weather.csv",row.names=FALSE)
  write.csv(cleaned_weather$weather,"data/Bonn_chillR_weather.csv",row.names=FALSE)
}

```














------------------------------------------------------------------------

\
\
References
